Отличия виртуальной машины от докера

Виртуальная машина предоставляет возможность создать полностью изолированный компьютер, на который выделяется некоторое
количество оперативной памяти, ядер процессора, определяем сетевые интерфейсы какие то, можем так же эмулировать
дисководы и т.д

В общем максимально изолированный отдельный компьютер
Но так как это можно сказать отдельный компьютер то у нас достаточно много накладных расходов на его запуск это занимает
достаточно много места то есть например для запуска простого сервиса на подобии вывода это довольно ресурсоемкая
операция для относительно простых задач

Докер же работает в рамках хостовой машины, и позволяет запускать изолированные друг от друга приложения с точки зрения
зависимости но при этом не расходуя на запуск таких приложений много дополнительных расходов

Докер предоставляет более эффективную масштабируемую модель по отношению к виртуальным машинам

Скачать докер можно по ссылке https://docs.docker.com/desktop/

1. Что такое image (Образы докер контейнеров) - image укомплектованное и готовое к запуску приложение
но еще не запущенное, по сути это и отличает
его от контейнера. Образы докер контейнеров состоят из слоев, каждый слой это определенная команда которая меняет
состояние этого контейнера, такими слоями могут быть установка системных зависимостей, установка библиотек или
копирование исходного кода приложения, после того как запускается image создается сам контейнер.

2.Контейнер это изолированная копия запущенного приложения. Один и тот же image может быть запущен несколько раз
и тогда будет несколько изолированных друг от друга контейнеров.

'''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
Запуск и работа с образами

Образы докер находятся на сайте - https://hub.docker.com/

docker run hello-world - Запуск образа
docker pull hello-world - Загрузка образа
docker ps - Вывод всех запущенных контейнеров
docker stop <ID CONTAINER> - остановка контейнера
docker image ls - просмотр образов
docker image rm <ID IMAGE> - Удаление образа
docker run -e POSTGRES_PASSWORD=postgres -d postgres запуск postgres в фоновом режиме и он отдает id контейнера
docker logs <ID CONTAINER> - просмотр логов контейнера он выдает всю пачку а это не всегда удобно
docker logs <ID CONTAINER> -f - опция -f позволяет выводить не просто пачку логов которая доступна на данный момент
а идет подсоединение к контейнеру и происходит вывод всех логов которые выводит этот контейнер в системный output
Например можем смотреть у nginx куда идет на данный момент весь трафик и каждый раз не писать docker logs
docker logs <ID CONTAINER> -f --tail - tail когда мы хотим вывести какое то определенное количество строк в конце
например когда мы хотим просмотреть последние 250 строк,  --tail 250

docker inspect <ID CONTAINER> - Выдает всю мета информацию которая есть по этому контейнеру, такие как переменные среды
конфиги и т.д, и там можно найти ip address контейнера к которому подсоединится!

Важно!!! Каждый запуск нового контейнера не сохраняет состояние предыдущего

'''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
Сохранение докер контейнером каких либо данных

Это не обязательно но когда у нас Контейнеры с приложениями которые хранят persistent данные например Redis, Postgres,
Mongo то логично при рестарте контейнера не хотелось бы терять при каждый раз данные, про некую абстракцию щас и будет
идти речь

volumes - позволяет прокидывать какие то хранилища данных в этот контейнер и делать его постоянным

для того что бы создать volumes существует опция -v и после пишем название где мы будем хранить данные
docker run -e POSTGRES_PASSWORD=postgres -p '5432:5432' -v pg_data:var/lib/postgresql/data -d postgres

тут у нас pg_data:var/lib/postgresql/data  pg_data bp локальной машины будет смотреть в докер контейнер

для проверки в пай чарм можно создать таблицу и остановить контейнер и после остановки контейнера и запуска заного
этого volumes у нас таблица останется

Узнать где он лежит физически на хостовой машине можно с помощью команды - docker volume ls

После пишем - docker volume inspect <имя volume> - и там можно увидеть где именно лежит физически папка

Удалить можно командой - docker volume rm <id volume>

*** docker exec <ID CONTAINER> OR <NAME CONTAINER> и после она принимает команду которую мы хотим выполнить
Базовые команды для изменения уже чего либо в самом контейнере - docker exec -it <id container> с помощью этой команды
мы оказываемся в bash нашего контейнера тут мы можем создать супер юзера, накатить миграции, накатить бекап на имеющуюся
базу данных пустую.
Еще мы можем узнать какой контейнер сколько потребляет памяти - docker stats
****


* Dockerfile - это файл в котором описываются все команды которые позволяет создать финальный докер image *

!!!Многоэтапные (multi-stage builds) сборки в Docker - позволяет создавать докер файл в несколько этапов и эти сами этапы
переиспользовать. Концептуально это необходимо для того что бы мы могли делать различные варианты докер образов
Например если есть пример докер образа в котором есть зависимости обработки тестов то понятно в продакшене эти тесты не
нужны, и вот тут мы делаем какой то базовый образ в котором установленны все системные зависимости дальше на основе
базового образа есть образ для тестов, там мы устанавливаем зависимости с development зависимостями, а production мы
устанавливаем только production зависимости.!!!

FROM ubuntu:18.04 as base
RUN apt-get update
RUN apt-get install -y python3 python3-pip
COPY main.py /main.py
CMD ["python3", "/main.py"]

docker build -f docker/Dockerfile .
docker build -f docker/Dockerfile -t test . Создали образ с названием тега test

После того как мы запустим докер контейнер с названием тега то он будет смотреть по слоям то что некоторые из них уже
за кэшированные, по этому заново мы на это время уже не тратим.

"credsStore": "desktop",
5T#*Z,TkeE6uk2@

""" multi-stage builds """

FROM ubuntu:18.04 as base
RUN apt-get update
RUN apt-get install -y python3 python3-pip

FROM base as development
COPY main.py /main.py
CMD ["python3", "/main.py"]

FROM development as production
COPY prod.py /prod.py
CMD ["python3", "/prod.py"]

тут у нас 3 отдельных stage, таким образом при создании и запуске образа он запустит продакшн версию

так же сделаем image в котором мы остановимся на этапе development - Для этого у команды build есть опция --target
и дальше мы указываем желаемый stage нашего build

docker build -f docker/Dockerfile -t test --target development . <- Команда

""""""""
docker-compose - это дополнительная утилита помогающая запускать и сразу менеджерить несколько контейнеров

1. Мы указываем версию docker compose нашего
2. В директиве services перечислить все сервисы которые хотим запускать

version: "3.9"


services:
    server:
    build:
        context: .
        dockerfile: docker/Dockerfile
    ports:
        - "8000:8000"
    environment:
        ENV: production
    networks:
        - postgres

    postgres:
        image: postgres:15.1 # Указываем название image который будем запускать
        environment:
            POSTGRES_USER: ${POSTGRES_USER:-postgres}
            POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
            PGDATA: /data/postgres
        volumes:
            - postgres:/data/postgres
        ports:
            - "5432:5432" # Позволяет пробрасывать порты из докер контейнера на локальную тачку
        networks: # связь между контейнерами так сказать мы их засовываем в один network таким образом они общаются
            - postgres
        env_file:
            - .env # Позволяет указать файл в котором будут все переменные среды
        restart: unless-stopped

networks:
    postgres:

volumes:
    postgres:


и запуск командой - docker-compose up -d postgres
остановка - docker-compose stop postgres
убить контейнер - docker-compose down
build - docker-compose build server аналог команды docker build








